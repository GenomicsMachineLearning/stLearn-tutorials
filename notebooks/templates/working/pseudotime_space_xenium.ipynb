{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e573cb-1af2-4a05-b83e-9b2c82e2c828",
   "metadata": {},
   "source": [
    "## Xenium data analysis with spatial trajectories inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087baaf-070f-4f80-8f29-6f63f30a0a91",
   "metadata": {},
   "source": [
    "We will go through the tutorial on how to use stLearn to perform clustering (with or without imputation) and spatial trajectories inference with Xenium data from 10X Genomics. The main dataset we are working on is the breast cancer tumor microenvironment. You can download it here: https://www.10xgenomics.com/products/xenium-in-situ/preview-dataset-human-breast "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b6ce0b-52b6-4068-8196-c342df744fdf",
   "metadata": {},
   "source": [
    "### 1. Loading library"
   ]
  },
  {
   "cell_type": "code",
   "id": "362d3b9b-345e-4a21-84c9-95c6c6655f73",
   "metadata": {},
   "source": [
    "import scanpy as sc\n",
    "import stlearn as st\n",
    "\n",
    "st.settings.set_figure_params(dpi=120)\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "library_id = \"Xenium_FFPE_Human_Breast_Cancer_Rep1\"",
   "id": "1ff5ec0b0eddd611",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "st.datasets.xenium_sge(library_id=library_id, include_hires_tiff=True)",
   "id": "245959ae12c8256f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "291a93b0-cd0b-4d0d-a2cb-7cbc9800d846",
   "metadata": {},
   "source": [
    "### 2. Reading Xenium data\n",
    "\n",
    "You can download all the data in the 10X Genomics resource webpage. For H&E image, because it was generated separately with the main xenium data, then you need to perform the registration by your self. Here we provide an example of a H&E image which is performed a manual registration by Dr. Soo Hee Lee. You can download it here: [Link](https://www.dropbox.com/s/th6tqqgbv27o3fk/CS1384_post-CS0_H%26E_S1A_RGB-shlee-crop.png?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0da7e84-4444-4a7d-9e1d-cdc674b76810",
   "metadata": {},
   "source": [
    "data_dir = st.settings.datasetdir / \"Xenium_FFPE_Human_Breast_Cancer_Rep1\"\n",
    "\n",
    "adata = st.ReadXenium(feature_cell_matrix_file=data_dir / \"cell_feature_matrix.h5\",\n",
    "                      cell_summary_file=data_dir / \"cells.csv.gz\",\n",
    "                      library_id=library_id,\n",
    "                      image_path=data_dir / \"he_image.ome.tif\",\n",
    "                      scale=1,\n",
    "                      spot_diameter_fullres=15,\n",
    "                      alignment_matrix_file=data_dir / \"he_imagealignment.csv\",\n",
    "                      experiment_xenium_file=data_dir / \"experiment.xenium\",\n",
    "                      )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import stlearn\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "def new_ReadXenium(\n",
    "        feature_cell_matrix_file: Union[str, Path],\n",
    "        cell_summary_file: Union[str, Path],\n",
    "        image_path: Union[Path, None] = None,\n",
    "        library_id: Union[str, None] = None,\n",
    "        scale: float = 1.0,\n",
    "        quality: str = \"hires\",\n",
    "        spot_diameter_fullres: float = 15,\n",
    "        background_color: str = \"white\",\n",
    "        alignment_matrix_file: Union[str, Path, None] = None,\n",
    "        pixel_size_microns: float = 0.2125,\n",
    "        coordinate_space: str = \"xenium\"  # \"xenium\" or \"image\"\n",
    ") -> \"AnnData\":\n",
    "    \"\"\"\\\n",
    "    Read Xenium data with optional H&E image alignment\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_cell_matrix_file\n",
    "        Path to feature cell count matrix file. Only support h5ad file now.\n",
    "    cell_summary_file\n",
    "        Path to cell summary CSV file.\n",
    "    image_path\n",
    "        Path to image. Only need when loading full resolution image.\n",
    "    library_id\n",
    "        Identifier for the Xenium library. Can be modified when concatenating multiple\n",
    "        adata objects.\n",
    "    scale\n",
    "        Set scale factor.\n",
    "    quality\n",
    "        Set quality that convert to stlearn to use. Store in\n",
    "        anndata.obs['imagecol' & 'imagerow']\n",
    "    spot_diameter_fullres\n",
    "        Diameter of spot in full resolution\n",
    "    background_color\n",
    "        Color of the background. Only `black` or `white` is allowed.\n",
    "    alignment_matrix_file\n",
    "        Path to transformation matrix CSV file exported from Xenium Explorer.\n",
    "        If provided, coordinates will be transformed according to coordinate_space.\n",
    "    pixel_size_microns\n",
    "        Pixel size in microns (default 0.2125 for Xenium data).\n",
    "    coordinate_space\n",
    "        Target coordinate space: \"xenium\" (default) or \"image\".\n",
    "        - \"xenium\": Convert image coordinates to Xenium space\n",
    "        - \"image\": Convert Xenium coordinates to image space\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = pd.read_csv(cell_summary_file)\n",
    "    adata = scanpy.read_10x_h5(feature_cell_matrix_file)\n",
    "\n",
    "    # Get original spatial coordinates\n",
    "    spatial = metadata[[\"x_centroid\", \"y_centroid\"]].copy()\n",
    "\n",
    "    # Apply alignment transformation if provided\n",
    "    if alignment_matrix_file is not None:\n",
    "        spatial = apply_alignment_transformation(\n",
    "            spatial,\n",
    "            alignment_matrix_file,\n",
    "            pixel_size_microns,\n",
    "            coordinate_space\n",
    "        )\n",
    "\n",
    "    spatial.columns = [\"imagecol\", \"imagerow\"]\n",
    "    adata.obsm[\"spatial\"] = spatial.values\n",
    "\n",
    "    if scale is None:\n",
    "        max_coor = np.max(adata.obsm[\"spatial\"])\n",
    "        scale = 2000 / max_coor\n",
    "\n",
    "    if library_id is None:\n",
    "        library_id = \"Xenium_data\"\n",
    "\n",
    "    adata.obs[\"imagecol\"] = spatial[\"imagecol\"].values * scale\n",
    "    adata.obs[\"imagerow\"] = spatial[\"imagerow\"].values * scale\n",
    "\n",
    "    if image_path is not None:\n",
    "        stlearn.add.image(\n",
    "            adata,\n",
    "            library_id=library_id,\n",
    "            quality=quality,\n",
    "            imgpath=image_path,\n",
    "            scale=scale,\n",
    "        )\n",
    "    else:\n",
    "        # Create image\n",
    "        max_size = np.max([adata.obs[\"imagecol\"].max(), adata.obs[\"imagerow\"].max()])\n",
    "        max_size = int(max_size + 0.1 * max_size)\n",
    "\n",
    "        if background_color == \"black\":\n",
    "            image = Image.new(\"RGBA\", (max_size, max_size), (0, 0, 0, 0))\n",
    "        else:\n",
    "            image = Image.new(\"RGBA\", (max_size, max_size), (255, 255, 255, 255))\n",
    "        imgarr = np.array(image)\n",
    "\n",
    "        # Create spatial dictionary\n",
    "        adata.uns[\"spatial\"] = {}\n",
    "        adata.uns[\"spatial\"][library_id] = {}\n",
    "        adata.uns[\"spatial\"][library_id][\"images\"] = {}\n",
    "        adata.uns[\"spatial\"][library_id][\"images\"][quality] = imgarr\n",
    "        adata.uns[\"spatial\"][library_id][\"use_quality\"] = quality\n",
    "        adata.uns[\"spatial\"][library_id][\"scalefactors\"] = {}\n",
    "        adata.uns[\"spatial\"][library_id][\"scalefactors\"][\n",
    "            \"tissue_\" + quality + \"_scalef\"\n",
    "            ] = scale\n",
    "        adata.uns[\"spatial\"][library_id][\"scalefactors\"][\n",
    "            \"spot_diameter_fullres\"\n",
    "        ] = spot_diameter_fullres\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "def apply_alignment_transformation(\n",
    "        coordinates: pd.DataFrame,\n",
    "        alignment_matrix_file: Union[str, Path],\n",
    "        pixel_size_microns: float = 0.2125,\n",
    "        coordinate_space: str = \"xenium\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply transformation matrix to convert coordinates between spaces.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinates\n",
    "        DataFrame with columns ['x_centroid', 'y_centroid'] in microns\n",
    "    alignment_matrix_file\n",
    "        Path to transformation matrix CSV file from Xenium Explorer\n",
    "    pixel_size_microns\n",
    "        Pixel size in microns\n",
    "    coordinate_space\n",
    "        Target coordinate space: \"xenium\" or \"image\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Transformed coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    # Read transformation matrix\n",
    "    transform_mat = pd.read_csv(alignment_matrix_file, header=None).values\n",
    "\n",
    "    # Convert coordinates based on target space\n",
    "    if coordinate_space == \"image\":\n",
    "        # Convert Xenium coordinates to image space\n",
    "        # First convert microns to pixels\n",
    "        coords_pixels = coordinates.values / pixel_size_microns\n",
    "\n",
    "        # Use inverse transformation matrix\n",
    "        transform_mat_inv = np.linalg.inv(transform_mat)\n",
    "\n",
    "        # Apply transformation\n",
    "        coords_homogeneous = np.column_stack([coords_pixels, np.ones(len(coords_pixels))])\n",
    "        transformed_coords = np.dot(coords_homogeneous, transform_mat_inv.T)\n",
    "\n",
    "        # Extract x, y coordinates (ignore homogeneous coordinate)\n",
    "        result_coords = transformed_coords[:, :2]\n",
    "\n",
    "    elif coordinate_space == \"xenium\":\n",
    "        # Convert image coordinates to Xenium space\n",
    "        # Assuming input coordinates are in pixels, convert to homogeneous coordinates\n",
    "        coords_homogeneous = np.column_stack([coordinates.values, np.ones(len(coordinates))])\n",
    "\n",
    "        # Apply transformation\n",
    "        transformed_coords = np.dot(coords_homogeneous, transform_mat.T)\n",
    "\n",
    "        # Extract x, y coordinates and convert to microns\n",
    "        result_coords = transformed_coords[:, :2] * pixel_size_microns\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"coordinate_space must be 'xenium' or 'image'\")\n",
    "\n",
    "    # Return as DataFrame with original column names\n",
    "    return pd.DataFrame(result_coords, columns=coordinates.columns)\n",
    "\n",
    "\n",
    "def load_transformation_matrix(alignment_matrix_file: Union[str, Path]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load and return transformation matrix from CSV file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alignment_matrix_file\n",
    "        Path to transformation matrix CSV file from Xenium Explorer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        3x3 transformation matrix\n",
    "    \"\"\"\n",
    "    return pd.read_csv(alignment_matrix_file, header=None).values\n",
    "\n",
    "\n",
    "def convert_coordinates(\n",
    "        coordinates: np.ndarray,\n",
    "        transformation_matrix: np.ndarray,\n",
    "        pixel_size_microns: float = 0.2125,\n",
    "        from_space: str = \"xenium\",\n",
    "        to_space: str = \"image\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert coordinates between Xenium and image spaces.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinates\n",
    "        Array of coordinates (N x 2) in microns (if from Xenium) or pixels (if from image)\n",
    "    transformation_matrix\n",
    "        3x3 transformation matrix from Xenium Explorer\n",
    "    pixel_size_microns\n",
    "        Pixel size in microns\n",
    "    from_space\n",
    "        Source coordinate space: \"xenium\" or \"image\"\n",
    "    to_space\n",
    "        Target coordinate space: \"xenium\" or \"image\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Transformed coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    if from_space == \"xenium\" and to_space == \"image\":\n",
    "        # Convert microns to pixels\n",
    "        coords_pixels = coordinates / pixel_size_microns\n",
    "\n",
    "        # Use inverse transformation matrix\n",
    "        transform_mat_inv = np.linalg.inv(transformation_matrix)\n",
    "\n",
    "        # Apply transformation\n",
    "        coords_homogeneous = np.column_stack([coords_pixels, np.ones(len(coords_pixels))])\n",
    "        transformed_coords = np.dot(coords_homogeneous, transform_mat_inv.T)\n",
    "\n",
    "        return transformed_coords[:, :2]\n",
    "\n",
    "    elif from_space == \"image\" and to_space == \"xenium\":\n",
    "        # Apply transformation\n",
    "        coords_homogeneous = np.column_stack([coordinates, np.ones(len(coordinates))])\n",
    "        transformed_coords = np.dot(coords_homogeneous, transformation_matrix.T)\n",
    "\n",
    "        # Convert pixels to microns\n",
    "        return transformed_coords[:, :2] * pixel_size_microns\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid coordinate space combination\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "# Load Xenium data with H&E alignment\n",
    "adata = ReadXenium(\n",
    "    feature_cell_matrix_file=\"cell_feature_matrix.h5\",\n",
    "    cell_summary_file=\"cells.csv\",\n",
    "    image_path=\"he_image.jpg\",\n",
    "    alignment_matrix_file=\"imagealignment.csv\",\n",
    "    coordinate_space=\"image\"  # Convert to image coordinate space\n",
    ")\n",
    "\n",
    "# Or manually convert coordinates\n",
    "transform_matrix = load_transformation_matrix(\"imagealignment.csv\")\n",
    "xenium_coords = np.array([[5372.5, 12779.5]])  # Example coordinates in microns\n",
    "image_coords = convert_coordinates(\n",
    "    xenium_coords,\n",
    "    transform_matrix,\n",
    "    from_space=\"xenium\",\n",
    "    to_space=\"image\"\n",
    ")\n",
    "\"\"\""
   ],
   "id": "6d9a1758e51ccf14",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3fd16a0d-243d-49fe-b92c-c012950c83b8",
   "metadata": {},
   "source": [
    "adata"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef765563-ea21-4ce2-b86c-a4aec9709b5e",
   "metadata": {},
   "source": [
    "### 3. Preprocessing\n",
    "\n",
    "Here, we use scanpy to perform several steps of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac906cec-fb74-4b3c-843b-2bb8c4d0f465",
   "metadata": {},
   "source": [
    "# Filter genes and cells with at least 10 counts\n",
    "sc.pp.filter_genes(adata, min_counts=10)\n",
    "sc.pp.filter_cells(adata, min_counts=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c62f3f11-0333-4964-af99-e277b529c133",
   "metadata": {},
   "source": [
    "# Store the raw data for using PSTS\n",
    "adata.raw = adata"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f42b56df-4c33-4a8f-af05-62f63e62754d",
   "metadata": {},
   "source": [
    "# Normalization data\n",
    "sc.pp.normalize_total(adata)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0bb9badb-99fe-4754-b008-21caf4881327",
   "metadata": {},
   "source": [
    "After normalization, we have two options. One is using log transformation or square root transformation (recommend by the 10X team)"
   ]
  },
  {
   "cell_type": "code",
   "id": "bad6b305-2f7c-420c-94e8-f219f588f925",
   "metadata": {},
   "source": [
    "# Squareroot normalize transcript counts. We need to deal with sparse matrix of .X\n",
    "\n",
    "adata.X = np.sqrt(adata.X.toarray()) + np.sqrt(adata.X.toarray() + 1)\n",
    "# If the matrix is small, we don't need to convert to numpy array. I believe, Xenium data is always large \n",
    "# adata.X = csr_array(np.sqrt(adata.X) + np.sqrt(adata.X + 1))\n",
    "\n",
    "# If you want to use log transformation, please use:\n",
    "# st.pp.log1p(adata)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e272c4bc-c2dd-4ecc-8f8c-9c75b24c2215",
   "metadata": {},
   "source": [
    "# Run PCA\n",
    "st.em.run_pca(adata, n_comps=50, random_state=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0fad014e-7840-4389-8fdd-8c38ac4343ea",
   "metadata": {},
   "source": [
    "##### Apply stSME (optional)\n",
    "\n",
    "stSME is optional as an imputation function. Due to the scope of this tutorial, we will not use it here, but we recommend you run if you have an H&E image in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8d11278-47ae-4f04-9688-43dc25ff3201",
   "metadata": {},
   "source": [
    "# apply stSME to normalise log transformed data\n",
    "# st.spatial.SME.SME_normalize(adata, use_data=\"raw\")\n",
    "# adata.X = adata.obsm['raw_SME_normalized']\n",
    "# st.pp.scale(adata)\n",
    "# st.em.run_pca(adata,n_comps=50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4ff1059-041e-496e-acf3-bb6a6fed3478",
   "metadata": {},
   "source": [
    "# Compute neighborhood graph of cells using the PCA representation\n",
    "st.pp.neighbors(adata, n_neighbors=25, use_rep='X_pca', random_state=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a51b626d-3756-4073-94f5-c563ce57b007",
   "metadata": {},
   "source": [
    "### 3. Clustering\n",
    "\n",
    "Here we use `louvain` clustering. You also can use `leiden` clustering method with `scanpy.tl.leiden`."
   ]
  },
  {
   "cell_type": "code",
   "id": "e884662c-4b49-4b71-9b30-b2c1aa0943a1",
   "metadata": {},
   "source": "st.tl.clustering.louvain(adata, random_state=0)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9f85f4c4-32b3-42b5-bcd0-67ebaaec5134",
   "metadata": {},
   "source": [
    "We can plot the clustering result: "
   ]
  },
  {
   "cell_type": "code",
   "id": "2c6c5bf0-ba7f-44f1-94a0-44a943551965",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "st.pl.cluster_plot(adata, use_label=\"louvain\", image_alpha=1, size=1, cell_alpha=0.5, show_image=True, show_axis=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e7c246b-ea26-4204-9345-525ec840bf39",
   "metadata": {},
   "source": [
    "You can crop a region of interest with `zoom_coord` parameter."
   ]
  },
  {
   "cell_type": "code",
   "id": "9a6f54e6-0741-4bda-9a8a-ee4d58e96329",
   "metadata": {},
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "st.pl.cluster_plot(adata, use_label=\"louvain\",\n",
    "                   image_alpha=0.2, size=10,\n",
    "                   cell_alpha=0.9,\n",
    "                   zoom_coord=(17000.0, 18500.0, 7500.0, 8900.0),\n",
    "                   show_color_bar=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cbbae164-e393-4254-ab6c-0503e1f2903f",
   "metadata": {},
   "source": [
    "### 4. PSeudo-Time-Space (PSTS) for spatial trajectory analysis\n",
    "\n",
    "We provide PSTS for spatial trajectory analysis.\n",
    "\n",
    "The first step is to select the root index. We allow the user to automatically select the index of the cell but still need to input which cluster should be the root cluster in your biological question.\n",
    "\n",
    "In this tutorial, we focus on the cancer progression from Ductal carcinoma in situ (DCIS) to Invasive ductal carcinoma (IDC). That is why we choose the root cluster `6` as the DCIS cluster. "
   ]
  },
  {
   "cell_type": "code",
   "id": "7ca02c42-d5f8-4a89-afdc-b60993270ad1",
   "metadata": {},
   "source": [
    "adata.uns[\"iroot\"] = st.spatial.trajectory.set_root(\n",
    "    adata,\n",
    "    use_label=\"louvain\",\n",
    "    cluster=\"4\",\n",
    "    use_raw=True\n",
    ")\n",
    "adata.uns[\"iroot\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c048827-e996-454f-8c35-b51ec10241ec",
   "metadata": {},
   "source": [
    "For the `pseudotime` function, we are based on the diffusion pseudotime algorithm to initialize the pseudotime for trajectory at the gene expression level. `pseudotimespace_global` is the function for incorporating the spatial information to construct the (meta) trajectory in the spatial context."
   ]
  },
  {
   "cell_type": "code",
   "id": "c201f7e9-688b-4a00-b8e4-5249174a623c",
   "metadata": {},
   "source": "st.spatial.trajectory.pseudotime(adata, eps=50, use_rep=\"X_pca\", use_label=\"louvain\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9623a3e6-78fe-4fde-ae0c-574b09068d6b",
   "metadata": {},
   "source": [
    "In this dataset, the IDC cluster we are looking for is the one on the edge of ducts. This part is the first layer of invasive cancer cells starting from DCIS. That's how we choose cluster `10` for the IDC."
   ]
  },
  {
   "cell_type": "code",
   "id": "73c894cf-42b1-4428-952c-d26723d0bbd6",
   "metadata": {},
   "source": "st.spatial.trajectory.pseudotimespace_global(adata, use_label=\"louvain\", list_clusters=[\"4\", \"9\"])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18142525-f7cc-4f25-8bdc-b448d7c654d0",
   "metadata": {},
   "source": [
    "After construct the spatial trajectories from DCIS to IDC cluster. We can observe multiple meta-trajectories with sub-clusters which generated by spatial feature. With `tree_plot`, you can show all of the detail sub-clusters ids."
   ]
  },
  {
   "cell_type": "code",
   "id": "6f212baf-0218-4a35-9a60-6db8a1fa2e7a",
   "metadata": {},
   "source": "st.pl.trajectory.tree_plot(adata, figsize=(10, 20), ncols=5)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "629a1f58-3b6f-4417-8ed4-43291b2cccc3",
   "metadata": {},
   "source": "Now, we can crop and discover the transition genes of sub-clusters meta-trajectory"
  },
  {
   "cell_type": "code",
   "id": "d9a64e07-046e-4725-98f8-504d94bda95f",
   "metadata": {},
   "source": [
    "st.pl.cluster_plot(\n",
    "    adata,\n",
    "    use_label=\"louvain\",\n",
    "    show_trajectories=True,\n",
    "    list_clusters=[\"4\", \"9\"],\n",
    "    show_subcluster=True,\n",
    "    zoom_coord=(17000.0, 18500.0, 7500.0, 8900.0),\n",
    "    show_node=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ac76bca-1d60-4668-b66a-7eac748f2b79",
   "metadata": {},
   "source": "Finding the transition markers of `clade_3019`"
  },
  {
   "cell_type": "code",
   "id": "5ab37b41-eac5-44b9-bbff-5475850a2a13",
   "metadata": {},
   "source": "st.spatial.trajectory.detect_transition_markers_clades(adata, clade=3019, use_raw_count=False, cutoff_spearman=0.1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "643f1d92-018e-4535-b8b8-c70a6817551c",
   "metadata": {},
   "source": [
    "Plot the transition markers, red color is down-regulated gene, blue color is up-regulated gene"
   ]
  },
  {
   "cell_type": "code",
   "id": "89e29c8c-78df-4986-b77f-a05647e8dc35",
   "metadata": {},
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "st.pl.trajectory.transition_markers_plot(adata, top_genes=20, trajectory=\"clade_3019\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4d64c792-f71e-4f71-a6f0-25380ec9e87d",
   "metadata": {},
   "source": [
    "We can observe some keratinocytes family genes here as the progression markers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7957747-18dd-4686-a3ca-138edf597cbc",
   "metadata": {},
   "source": [
    "### Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547ad07-4844-4a4d-992b-9677908511b9",
   "metadata": {},
   "source": [
    "We would like to thank Soo Hee Lee and 10X Genomics team for their able support, contribution and feedback to this tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
